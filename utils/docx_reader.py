from docx import Document
from loguru import logger
from pathlib import Path
import re
import json

# ============================================================
# üé≠ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç—ë—Ä–æ–≤ –∏–∑ actors_list.json
# ============================================================

ACTOR_NAMES = set()

def _load_actor_names():
    """–ü—Ä–æ–±—É–µ—Ç –Ω–∞–π—Ç–∏ actors_list.json –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö"""
    search_paths = [
        Path(__file__).resolve().parent / "actors_list.json",                     # —Ä—è–¥–æ–º —Å —Ñ–∞–π–ª–æ–º
        Path(__file__).resolve().parent / "data" / "actors_list.json",            # utils/data/
        Path(__file__).resolve().parents[1] / "data" / "actors_list.json",        # ../data/
        Path(__file__).resolve().parents[1] / "actors_list.json",                 # –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
    ]
    for path in search_paths:
        if path.exists():
            try:
                with open(path, "r", encoding="utf-8") as f:
                    names = {x.strip().lower() for x in json.load(f) if x.strip()}
                    logger.info(f"üé≠ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∞–∫—Ç—ë—Ä–æ–≤: {len(names)} –∏–∑ {path}")
                    return names
            except Exception as e:
                logger.warning(f"‚ö† –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {path}: {e}")
    logger.warning("‚ö† actors_list.json –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî fallback –∫ –±–∞–∑–æ–≤–æ–º—É –ø–∞—Ä—Å–∏–Ω–≥—É.")
    return set()

ACTOR_NAMES = _load_actor_names()

# ============================================================
# üß© –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ============================================================

def _extract_text_with_breaks(cell):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —è—á–µ–π–∫–∏ Word —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å—Ç—Ä–æ–∫"""
    try:
        lines = []
        for p in cell._element.xpath(".//w:p"):
            buf = []
            for r in p.xpath(".//w:r"):
                for t in r.xpath(".//w:t"):
                    if t.text:
                        buf.append(t.text)
                if r.xpath(".//w:br"):
                    buf.append("\n")
            line = "".join(buf).strip()
            if line:
                lines.append(line)
        text = "\n".join(lines).replace("\r", "\n").strip()
        return text
    except Exception as e:
        logger.warning(f"‚ö† –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —è—á–µ–π–∫–∏: {e}")
        return cell.text.strip() if cell.text else ""


_SPLIT_RE = re.compile(r"[\n\r\u000b\u2028\u2029;,/\\]+")


def _split_people_blob(blob: str) -> list[str]:
    """–†–∞–∑–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–æ–∫—É –∞–∫—Ç—ë—Ä–æ–≤ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã"""
    if not blob:
        return []
    parts = [p.strip() for p in _SPLIT_RE.split(blob) if p.strip()]
    return parts


def _clean_actor_token(token: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –º—É—Å–æ—Ä–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–º—è"""
    token = re.sub(r"[%!\d.,]+", "", token)  # —É–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ, —Ü–∏—Ñ—Ä—ã
    token = token.strip()
    return token


def _try_split_concatenated(token: str) -> list[str]:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è —Ä–∞–∑–±–∏—Ç—å —Å–∫–ª–µ–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä '–ò–ª–∞–Ω–∞–ö—Å—é—à–∞')
    –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∏–º–µ–Ω–∞–º –∏–∑ ACTOR_NAMES.
    """
    if not ACTOR_NAMES:
        return [token]
    low = token.lower()
    found = []
    i = 0
    while i < len(low):
        match = None
        for name in sorted(ACTOR_NAMES, key=len, reverse=True):
            if low.startswith(name, i):
                found.append(name)
                i += len(name)
                match = True
                break
        if not match:
            i += 1
    if len(found) > 1:
        return [n.capitalize() for n in found]
    return [token]


# ============================================================
# üéØ –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–µ—Ä –∞–∫—Ç—ë—Ä–æ–≤
# ============================================================

def parse_actors(raw: str) -> list[dict]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç—ë—Ä–æ–≤ –∏ —Ç–µ–≥–∏:
      %  ‚Üí 'later'
      !  ‚Üí 'early'
      (–≥–∫), –≥–∫, –ì–∫, (–ì–ö), –≥ –∫ ‚Üí 'gk'
    """
    if not raw:
        return []

    result = []
    for token in _split_people_blob(raw):
        if not token.strip():
            continue
        tags = set()
        name = token.strip()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–≥–∏
        if "%" in name:
            tags.add("later")
        if "!" in name:
            tags.add("early")

        # –ü–æ–∏—Å–∫ –ª—é–±—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ "–≥–∫"
        if re.search(r"\(?\b–≥\s*–∫\b\)?", name, flags=re.IGNORECASE):
            tags.add("gk")

        # –£–±–∏—Ä–∞–µ–º –º–µ—Ç–∫–∏ –∏–∑ –∏–º–µ–Ω–∏
        name = re.sub(r"\(?\b–≥\s*–∫\b\)?", "", name, flags=re.IGNORECASE)
        name = _clean_actor_token(name)

        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Å–∫–ª–µ–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞
        names = _try_split_concatenated(name)

        for nm in names:
            nm = " ".join(nm.split())
            if nm:
                result.append({"name": nm, "tags": sorted(list(tags))})

    return result


# ============================================================
# üìò –ß—Ç–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
# ============================================================

def read_program(path: str):
    """–ß–∏—Ç–∞–µ—Ç –ø–µ—Ä–≤—É—é —Ç–∞–±–ª–∏—Ü—É –∏–∑ DOCX –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    logger.info(f"üìÑ –ß—Ç–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {path}")
    doc = Document(path)
    if not doc.tables:
        logger.error("‚ùå –í –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ—Ç —Ç–∞–±–ª–∏—Ü.")
        return []

    table = doc.tables[0]
    rows = table.rows
    if len(rows) < 2:
        logger.error("‚ùå –¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞.")
        return []

    data = []
    for i, row in enumerate(rows[1:], start=1):
        cells = row.cells
        texts = [_extract_text_with_breaks(c) for c in cells]
        if not any(texts):
            continue

        num = texts[0] if len(texts) > 0 else ""
        title = texts[1] if len(texts) > 1 else ""
        actors_raw = texts[2] if len(texts) > 2 else ""
        pp = texts[3] if len(texts) > 3 else ""  # –∫–æ–ª–æ–Ω–∫–∞ –ü–ü
        hire = texts[4] if len(texts) > 4 else ""
        responsible = texts[5] if len(texts) > 5 else ""
        kv = "–∫–≤" in (texts[6].lower() if len(texts) > 6 and texts[6] else "")

        entry = {
            "order": i,
            "num": num,
            "title": title,
            "actors_raw": actors_raw,
            "pp": pp,
            "hire": hire,
            "responsible": responsible,
            "kv": kv,
            "type": "–æ–±—ã—á–Ω—ã–π",
        }

        lower_title = title.lower()
        if "–ø—Ä–µ–¥–∫—É–ª–∏—Å—å–µ" in lower_title:
            entry["type"] = "–ø—Ä–µ–¥–∫—É–ª–∏—Å—å–µ"
        elif "—Å–ø–æ–Ω—Å–æ—Ä" in lower_title:
            entry["type"] = "—Å–ø–æ–Ω—Å–æ—Ä—ã"
        elif "—Ç—è–Ω—É—á" in lower_title:
            entry["type"] = "—Ç—è–Ω—É—á–∫–∞"

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞–∫—Ç—ë—Ä–æ–≤ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ –∏ –ü–ü
        main_actors = parse_actors(actors_raw)
        pp_actors = parse_actors(pp)

        merged_actors = {a["name"]: set(a["tags"]) for a in main_actors}
        for pa in pp_actors:
            name = pa["name"]
            tags = set(pa["tags"])
            if name in merged_actors:
                merged_actors[name].update(tags)
            else:
                merged_actors[name] = tags

        entry["actors"] = [
            {"name": name, "tags": sorted(list(tags))} for name, tags in merged_actors.items()
        ]

        data.append(entry)

    logger.info(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(data)} —Å—Ç—Ä–æ–∫.")
    return data


# ============================================================
# üß™ –¢–µ—Å—Ç
# ============================================================

if __name__ == "__main__":
    import json
    test_str = "–ò–ª–∞–Ω–∞(–≥–∫)! –ö—Å—é—à–∞ –ì–∫% –ü—É—à–∫–∏–Ω (–ì–ö)! –ë—Ä–µ–∫–æ—Ç–∫–∏–Ω –≥ –∫%%"
    print(json.dumps(parse_actors(test_str), ensure_ascii=False, indent=2))
