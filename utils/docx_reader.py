from docx import Document
from loguru import logger
import re


def _extract_text_with_breaks(cell):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —è—á–µ–π–∫–∏ Word —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å—Ç—Ä–æ–∫"""
    try:
        lines = []
        # –°—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –∞–±–∑–∞—Ü—ã –∏ <w:br/> –≤–Ω—É—Ç—Ä–∏ —è—á–µ–π–∫–∏
        for p in cell._element.xpath(".//w:p"):
            buf = []
            for r in p.xpath(".//w:r"):
                for t in r.xpath(".//w:t"):
                    if t.text:
                        buf.append(t.text)
                if r.xpath(".//w:br"):
                    buf.append("\n")
            line = "".join(buf).strip()
            if line:
                lines.append(line)
        text = "\n".join(lines)
        text = text.replace("\r", "\n").strip()
        return text
    except Exception as e:
        logger.warning(f"‚ö† –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —è—á–µ–π–∫–∏: {e}")
        return cell.text.strip() if cell.text else ""


# –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä –¥–ª—è –∞–∫—Ç—ë—Ä–æ–≤
_SPLIT_RE = re.compile(r"[\n\r\u000b\u2028\u2029;,/\\]+")


def _split_people_blob(blob: str) -> list[str]:
    """–†–∞–∑–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–æ–∫—É –∞–∫—Ç—ë—Ä–æ–≤ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞"""
    if not blob:
        return []
    parts = [p.strip() for p in _SPLIT_RE.split(blob) if p.strip()]
    return parts


def parse_actors(raw: str) -> list[dict]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç—ë—Ä–æ–≤ –∏ —Ç–µ–≥–∏:
      %  ‚Üí 'later'
      !  ‚Üí 'early'
      (–≥–∫) ‚Üí 'gk' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π)
    –ú–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ–≥–æ–≤ —Å—Ä–∞–∑—É.
    """
    if not raw:
        return []

    result = []
    for token in _split_people_blob(raw):
        name = token.strip()
        tags = set()

        lname = name.lower()
        if "(–≥–∫)" in lname or "(–≥ –∫)" in lname:
            tags.add("gk")
            name = (
                name.replace("(–≥–∫)", "")
                .replace("(–ì–ö)", "")
                .replace("(–≥ –∫)", "")
                .replace("(–ì –ö)", "")
                .strip()
            )

        if "%" in name:
            tags.add("later")
            name = name.replace("%", "").strip()

        if "!" in name:
            tags.add("early")
            name = name.replace("!", "").strip()

        name = " ".join(name.split())
        if name:
            result.append({"name": name, "tags": list(tags)})

    return result


def read_program(path: str):
    """–ß–∏—Ç–∞–µ—Ç –ø–µ—Ä–≤—É—é —Ç–∞–±–ª–∏—Ü—É –∏–∑ DOCX –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    logger.info(f"üìÑ –ß—Ç–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {path}")
    doc = Document(path)
    if not doc.tables:
        logger.error("‚ùå –í –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ—Ç —Ç–∞–±–ª–∏—Ü.")
        return []

    table = doc.tables[0]
    rows = table.rows
    if len(rows) < 2:
        logger.error("‚ùå –¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞.")
        return []

    data = []
    for i, row in enumerate(rows[1:], start=1):
        cells = row.cells
        texts = [_extract_text_with_breaks(c) for c in cells]
        if not any(texts):
            continue

        num = texts[0] if len(texts) > 0 else ""
        title = texts[1] if len(texts) > 1 else ""
        actors_raw = texts[2] if len(texts) > 2 else ""
        pp = texts[3] if len(texts) > 3 else ""  # –∫–æ–ª–æ–Ω–∫–∞ –ü–ü
        hire = texts[4] if len(texts) > 4 else ""
        responsible = texts[5] if len(texts) > 5 else ""
        kv = "–∫–≤" in (texts[6].lower() if len(texts) > 6 and texts[6] else "")

        entry = {
            "order": i,
            "num": num,
            "title": title,
            "actors_raw": actors_raw,
            "pp": pp,
            "hire": hire,
            "responsible": responsible,
            "kv": kv,
            "type": "–æ–±—ã—á–Ω—ã–π",
        }

        lower_title = title.lower()
        if "–ø—Ä–µ–¥–∫—É–ª–∏—Å—å–µ" in lower_title:
            entry["type"] = "–ø—Ä–µ–¥–∫—É–ª–∏—Å—å–µ"
        elif "—Å–ø–æ–Ω—Å–æ—Ä" in lower_title:
            entry["type"] = "—Å–ø–æ–Ω—Å–æ—Ä—ã"
        elif "—Ç—è–Ω—É—á" in lower_title:
            entry["type"] = "—Ç—è–Ω—É—á–∫–∞"

        # --- –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∞–∫—Ç—ë—Ä–æ–≤ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ –∏ –ü–ü ---
        main_actors = parse_actors(actors_raw)
        pp_actors = parse_actors(pp)

        # –°–ª–∏–≤–∞–µ–º, –æ–±—ä–µ–¥–∏–Ω—è—è —Ç–µ–≥–∏ —É –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∏–º—ë–Ω
        merged_actors = {a["name"]: set(a["tags"]) for a in main_actors}
        for pa in pp_actors:
            name = pa["name"]
            tags = set(pa["tags"])
            if name in merged_actors:
                merged_actors[name].update(tags)
            else:
                merged_actors[name] = tags

        entry["actors"] = [
            {"name": name, "tags": sorted(list(tags))} for name, tags in merged_actors.items()
        ]

        data.append(entry)

    logger.info(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(data)} —Å—Ç—Ä–æ–∫.")
    return data


# ===== –£–î–ê–õ–ò–¢–¨ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞ =====
if __name__ == "__main__":
    import json

    test_str = "–ë—Ä–µ–∫–æ—Ç–∫–∏–Ω%%!\n–°–æ–∫–æ–ª–æ–≤!(–≥–∫)\n–ü—è—Ç–∫–æ–≤%\n–ü—É—à–∫–∏–Ω(–≥–∫)"
    result = parse_actors(test_str)
    print(json.dumps(result, ensure_ascii=False, indent=2))
